{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca871f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import pandas as pd\n",
    "import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "056b65dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Videos/5003_I.MOV is a valid file. Proceed with processing.\n"
     ]
    }
   ],
   "source": [
    "MODEL = 1  # 1 = Lite model, 2 = Full model\n",
    "video_path = \"../Videos/5003_I.MOV\"\n",
    "video_extensions = [\"*.mp4\", \"*.avi\", \"*.MOV\"]\n",
    "\n",
    "if os.path.exists(video_path) == True:\n",
    "    print(f\"{video_path} is a valid file. Proceed with processing.\")\n",
    "else:\n",
    "    raise ValueError(f\"{video_path} does not exist. Try adding the entire file path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34058d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe components\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baa76350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 27147/27147 [15:48<00:00, 28.63frame/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with mp_holistic.Holistic(static_image_mode=False, model_complexity=MODEL, \n",
    "                          min_detection_confidence=0.4, min_tracking_confidence=0.4) as holistic:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Get the frame width and height from the video capture object\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # # Define the codec using VideoWriter_fourcc and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('output.avi', fourcc, fps, (frame_width, frame_height), isColor=True)\n",
    "    \n",
    "    for _ in tq.tqdm(range(total_frames), desc=\"Processing frames\", unit=\"frame\"):\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_number = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        time_ms = round((frame_number / fps) * 1000, 0)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # Convert the image color back to BGR for VideoWriter\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Draw the pose landmarks on the image\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "        \n",
    "        # # Write the frame into the file 'output.avi'\n",
    "        out.write(image)\n",
    "        \n",
    "        if results.pose_landmarks is not None:\n",
    "            right_shoulder_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER].x\n",
    "            right_shoulder_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER].y\n",
    "            left_shoulder_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER].x\n",
    "            left_shoulder_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER].y\n",
    "            right_elbow_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_ELBOW].x\n",
    "            right_elbow_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_ELBOW].y\n",
    "            left_elbow_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_ELBOW].x\n",
    "            left_elbow_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_ELBOW].y\n",
    "            right_wrist_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_WRIST].x\n",
    "            right_wrist_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_WRIST].y\n",
    "            left_wrist_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_WRIST].x\n",
    "            left_wrist_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_WRIST].y\n",
    "            right_eye_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_EYE].x\n",
    "            right_eye_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_EYE].y\n",
    "            left_eye_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EYE].x\n",
    "            left_eye_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EYE].y\n",
    "            nose_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x\n",
    "            nose_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y\n",
    "            right_index_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_INDEX].x\n",
    "            right_index_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_INDEX].y\n",
    "\n",
    "            data.append([time_ms, right_shoulder_x, right_shoulder_y, left_shoulder_x, left_shoulder_y, \n",
    "                        right_elbow_x, right_elbow_y, left_elbow_x, left_elbow_y, \n",
    "                        right_wrist_x, right_wrist_y, left_wrist_x, left_wrist_y, \n",
    "                        right_eye_x, right_eye_y, left_eye_x, left_eye_y, right_index_x, right_index_y,\n",
    "                        nose_x, nose_y])\n",
    "            \n",
    "                    \n",
    "        out.write(image)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ada8edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all keypoints, appended to final dataframe\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    \"time_ms\", \n",
    "    \"right_shoulder_x\", \"right_shoulder_y\", \n",
    "    \"left_shoulder_x\", \"left_shoulder_y\", \n",
    "    \"right_elbow_x\", \"right_elbow_y\", \n",
    "    \"left_elbow_x\", \"left_elbow_y\", \n",
    "    \"right_wrist_x\", \"right_wrist_y\", \n",
    "    \"left_wrist_x\", \"left_wrist_y\", \n",
    "    \"right_eye_x\", \"right_eye_y\", \n",
    "    \"left_eye_x\", \"left_eye_y\",\n",
    "    \"nose_x\", \"nose_y\",\n",
    "    \"right_index_x\", \"right_index_y\" \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a626cf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as ../Keypoints/5003_I_keypoints.csv\n"
     ]
    }
   ],
   "source": [
    "# Save DataFrame as CSV file\n",
    "csv_file_name = \"../Keypoints/\" + os.path.splitext(os.path.basename(video_path))[0] + \"_keypoints.csv\"\n",
    "df.to_csv(csv_file_name, index=False)\n",
    "print(f\"DataFrame saved as {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c5021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
