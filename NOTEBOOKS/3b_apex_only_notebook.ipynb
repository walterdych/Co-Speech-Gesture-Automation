{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <strong>3b: Apex Only Notebook |</strong>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to align data\n",
    "\n",
    "This Python function, `align_data`, is designed to align two dataframes: `mtdf` and `annotdf` which will contain the motiontracking data and the ELAN annotations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to align data\n",
    "def align_data(mtdf, annotdf):\n",
    "# Add a gesture ID column to the annotations dataframe\n",
    "    annotdf['gesture_id'] = range(1, len(annotdf) + 1)\n",
    "\n",
    "    # Create new columns in data_df for annotations and gesture IDs\n",
    "    mtdf['phase'] = None\n",
    "    mtdf['gesture_id'] = None\n",
    "\n",
    "    # Iterate over each row in the annotations dataframe\n",
    "    for _, row in annotdf.iterrows():\n",
    "        # Find the range of time in data_df that falls within the current annotation time\n",
    "        condition = (mtdf['time_ms'] >= row['start_time']) & (mtdf['time_ms'] <= row['end_time'])\n",
    "        \n",
    "        # Assign the annotation and gesture ID to these rows\n",
    "        mtdf.loc[condition, 'phase'] = row['phase']\n",
    "        mtdf.loc[condition, 'gesture_id'] = row['gesture_id']\n",
    "\n",
    "    return mtdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "phase_dir = '/n/kfranich_speech_l3/Lab/6000_EMA/processed_articulatory_data/video_processing/elan_phases/SN6014_ARTGEST_ENG'\n",
    "processed_dir = '/n/kfranich_speech_l3/Lab/6000_EMA/processed_articulatory_data/video_processing/speed_and_upsample/SN6014_ARTGEST_ENG'\n",
    "output_dir = '/n/kfranich_speech_l3/Lab/6000_EMA/processed_articulatory_data/video_processing/apex_annotated/SN6014_ARTGEST_ENG'\n",
    "\n",
    "# Output Structuring\n",
    "output_file = os.path.join(output_dir, os.path.basename(processed_file).replace('_processed_data.csv', '_final_annotations.csv'))\n",
    "\n",
    "# Get list of files in directories\n",
    "phase_files = glob.glob(os.path.join(phase_dir, '*.csv'))\n",
    "processed_files = glob.glob(os.path.join(processed_dir, '*.csv'))\n",
    "\n",
    "# List gathered files\n",
    "phase_files\n",
    "processed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match phase and processed files based on filenames\n",
    "matched_files = []\n",
    "for phase_file in phase_files:\n",
    "    basename = os.path.basename(phase_file).split('_extended_annotations.csv')[0]\n",
    "    for processed_file in processed_files:\n",
    "        if basename in processed_file:\n",
    "            matched_files.append((phase_file, processed_file))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each matched file pair\n",
    "for phase_file, processed_file in matched_files:\n",
    "    df_phase = pd.read_csv(phase_file)\n",
    "    df_processed = pd.read_csv(processed_file)\n",
    "\n",
    "    # Rename columns if necessary\n",
    "    df_phase.columns = ['start_time', 'end_time', 'phase']\n",
    "\n",
    "    # Main processing logic\n",
    "    df_processed = align_data(df_processed, df_phase)\n",
    "    df_processed = df_processed.drop(columns=['right_wrist_delta_x', 'right_wrist_delta_y', 'right_index_x',\n",
    "                                              'right_index_y', 'right_index_speed', 'right_index_delta_x','right_index_delta_y'])\n",
    "    filtered_df = df_processed.dropna(subset=['right_wrist_speed', 'phase'])\n",
    "    more_refined_apexes_df = pd.DataFrame(columns=['time_ms', 'right_wrist_speed', 'gesture_id', 'apex'])\n",
    "\n",
    "    for gesture_id in filtered_df['gesture_id'].dropna().unique():\n",
    "        gesture_data = filtered_df[filtered_df['gesture_id'] == gesture_id]\n",
    "        stroke_data = gesture_data[gesture_data['phase'].isin(['S', 'Stroke'])]\n",
    "        if len(stroke_data) == 0:\n",
    "            continue\n",
    "        dynamic_large_peak_threshold = stroke_data['right_wrist_speed'].mean() + stroke_data['right_wrist_speed'].std()\n",
    "        peaks, _ = find_peaks(stroke_data['right_wrist_speed'].values, height=dynamic_large_peak_threshold)\n",
    "        if len(peaks) > 0:\n",
    "            for peak in peaks:\n",
    "                subsequent_data = stroke_data['right_wrist_speed'].values[peak:]\n",
    "                if len(subsequent_data) > 1:\n",
    "                    min_speed_index = np.argmin(subsequent_data) + peak\n",
    "                    original_index = stroke_data.index[min_speed_index]\n",
    "                    stroke_data.loc[original_index, 'apex'] = 'AX'\n",
    "        else:\n",
    "            min_speed_index = np.argmin(stroke_data['right_wrist_speed'].values)\n",
    "            original_index = stroke_data.index[min_speed_index]\n",
    "            stroke_data.loc[original_index, 'apex'] = 'AX'\n",
    "        more_refined_apexes_df = more_refined_apexes_df._append(stroke_data)\n",
    "\n",
    "    # Save output\n",
    "    more_refined_apexes_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f'Done Processing {output_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
