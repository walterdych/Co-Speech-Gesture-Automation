{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <strong>3b: Apex Only Notebook |</strong>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to align data\n",
    "\n",
    "This Python function, `align_data`, is designed to align two dataframes: `mtdf` and `annotdf` which will contain the motiontracking data and the ELAN annotations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to align data\n",
    "def align_data(mtdf, annotdf):\n",
    "# Add a gesture ID column to the annotations dataframe\n",
    "    annotdf['gesture_id'] = range(1, len(annotdf) + 1)\n",
    "\n",
    "    # Create new columns in data_df for annotations and gesture IDs\n",
    "    mtdf['phase'] = None\n",
    "    mtdf['gesture_id'] = None\n",
    "\n",
    "    # Iterate over each row in the annotations dataframe\n",
    "    for _, row in annotdf.iterrows():\n",
    "        # Find the range of time in data_df that falls within the current annotation time\n",
    "        condition = (mtdf['time_ms'] >= row['start_time']) & (mtdf['time_ms'] <= row['end_time'])\n",
    "        \n",
    "        # Assign the annotation and gesture ID to these rows\n",
    "        mtdf.loc[condition, 'phase'] = row['phase']\n",
    "        mtdf.loc[condition, 'gesture_id'] = row['gesture_id']\n",
    "\n",
    "    return mtdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code cell, several directory paths are defined, and files within those directories are gathered:\n",
    "\n",
    "### Directory Definitions\n",
    "- `phase_dir`: The directory for the ELAN Phases data.\n",
    "- `processed_dir`: The directory for processed manual gesture data.\n",
    "- `output_dir`: The directory for output or annotated data.\n",
    "\n",
    "### Output File Path\n",
    "An `output_file` variable is created by joining `output_dir` with a modified version of `processed_file`. It replaces '_processed_data.csv' with '_final_annotations.csv' in the filename.\n",
    "\n",
    "### Gathering Files\n",
    "The `glob` library is used to get lists of files within the `phase_dir` and `processed_dir` directories. These lists are stored in the variables `phase_files` and `processed_files`, respectively.\n",
    "\n",
    "### List of Gathered Files\n",
    "Here are the lists of files found in the respective directories:\n",
    "- `phase_files`: Contains a list of files from the `phase_dir`.\n",
    "- `processed_files`: Contains a list of files from the `processed_dir`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "phase_dir = '/n/kfranich_speech_l3/Lab/6000_EMA/processed_articulatory_data/video_processing/elan_phases/SN6014_ARTGEST_ENG'\n",
    "processed_dir = '/n/kfranich_speech_l3/Lab/6000_EMA/processed_articulatory_data/video_processing/speed_and_upsample/SN6014_ARTGEST_ENG'\n",
    "output_dir = '/n/kfranich_speech_l3/Lab/6000_EMA/processed_articulatory_data/video_processing/apex_annotated/SN6014_ARTGEST_ENG'\n",
    "\n",
    "# Output Structuring\n",
    "output_file = os.path.join(output_dir, os.path.basename(processed_file).replace('_processed_data.csv', '_final_annotations.csv'))\n",
    "\n",
    "# Get list of files in directories\n",
    "phase_files = glob.glob(os.path.join(phase_dir, '*.csv'))\n",
    "processed_files = glob.glob(os.path.join(processed_dir, '*.csv'))\n",
    "\n",
    "# List gathered files\n",
    "phase_files\n",
    "processed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Phase and Processed Files\n",
    "\n",
    "- **Matching Logic**: A list called `matched_files` is initialized to store pairs of matched files.\n",
    "  \n",
    "- **Iteration**: The code iterates through each `phase_file` in the `phase_files` list.\n",
    "\n",
    "- **Filename Extraction**: For each `phase_file`, the code extracts the filename without the '_extended_annotations.csv' part using `os.path.basename(phase_file).split('_extended_annotations.csv')[0]`.\n",
    "\n",
    "- **Matching**: It then iterates through each `processed_file` in the `processed_files` list and checks if the extracted `basename` is present in the `processed_file`.\n",
    "\n",
    "- **Appending Matched Pairs**: If a match is found, a tuple containing the `phase_file` and the corresponding `processed_file` is appended to the `matched_files` list. The loop breaks after finding the first match for efficiency.\n",
    "\n",
    "This code effectively pairs up files from the `phase_dir` and `processed_dir` directories based on their filenames, allowing further processing or analysis of matched pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match phase and processed files based on filenames\n",
    "matched_files = []\n",
    "for phase_file in phase_files:\n",
    "    basename = os.path.basename(phase_file).split('_extended_annotations.csv')[0]\n",
    "    for processed_file in processed_files:\n",
    "        if basename in processed_file:\n",
    "            matched_files.append((phase_file, processed_file))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Matched File Pairs\n",
    "\n",
    "- **File Reading**: For each pair of matched files (`phase_file` and `processed_file`), the code reads the data from these CSV files into Pandas DataFrames using `pd.read_csv()`.\n",
    "\n",
    "- **Column Renaming**: If necessary, the code renames the columns of the `df_phase` DataFrame to 'start_time', 'end_time', and 'phase'.\n",
    "\n",
    "- **Main Processing Logic**: The core processing logic begins here. It uses a function named `align_data()` to align data in the `df_processed` DataFrame with the phase information in the `df_phase` DataFrame.\n",
    "\n",
    "- **Data Filtering**: A new DataFrame named `filtered_df` is created by dropping rows with missing values in the 'right_wrist_speed' and 'phase' columns.\n",
    "\n",
    "- **Gesture and Apex Detection**: The code iterates over unique 'gesture_id' values in the `filtered_df` DataFrame. For each gesture, it extracts relevant data, including 'Stroke' phase data. It calculates a dynamic peak threshold based on the mean and standard deviation of wrist speed during strokes. Using this threshold, it identifies peaks in the wrist speed data and marks them as 'AX' (apex). If no peaks are found, it selects the minimum speed point as the 'AX'. The resulting data is appended to the `more_refined_apexes_df` DataFrame.\n",
    "\n",
    "- **Output Saving**: The `more_refined_apexes_df` DataFrame is saved as a CSV file at the specified `output_file` path using `to_csv()`.\n",
    "\n",
    "- **Print Status Message**: A message is printed indicating the completion of processing for the current `output_file`.\n",
    "\n",
    "This code block effectively processes each matched file pair, aligns data, filters it, and detects apexes in the wrist speed data, saving the results in the specified output file. It appears to be part of a data preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each matched file pair\n",
    "for phase_file, processed_file in matched_files:\n",
    "    df_phase = pd.read_csv(phase_file)\n",
    "    df_processed = pd.read_csv(processed_file)\n",
    "\n",
    "    # Rename columns if necessary\n",
    "    df_phase.columns = ['start_time', 'end_time', 'phase']\n",
    "\n",
    "    # Main processing logic\n",
    "    df_processed = align_data(df_processed, df_phase)\n",
    "    df_processed = df_processed.drop(columns=['right_wrist_delta_x', 'right_wrist_delta_y', 'right_index_x',\n",
    "                                              'right_index_y', 'right_index_speed', 'right_index_delta_x','right_index_delta_y'])\n",
    "    filtered_df = df_processed.dropna(subset=['right_wrist_speed', 'phase'])\n",
    "    more_refined_apexes_df = pd.DataFrame(columns=['time_ms', 'right_wrist_speed', 'gesture_id', 'apex'])\n",
    "\n",
    "    for gesture_id in filtered_df['gesture_id'].dropna().unique():\n",
    "        gesture_data = filtered_df[filtered_df['gesture_id'] == gesture_id]\n",
    "        stroke_data = gesture_data[gesture_data['phase'].isin(['S', 'Stroke'])]\n",
    "        if len(stroke_data) == 0:\n",
    "            continue\n",
    "        dynamic_large_peak_threshold = stroke_data['right_wrist_speed'].mean() + stroke_data['right_wrist_speed'].std()\n",
    "        peaks, _ = find_peaks(stroke_data['right_wrist_speed'].values, height=dynamic_large_peak_threshold)\n",
    "        if len(peaks) > 0:\n",
    "            for peak in peaks:\n",
    "                subsequent_data = stroke_data['right_wrist_speed'].values[peak:]\n",
    "                if len(subsequent_data) > 1:\n",
    "                    min_speed_index = np.argmin(subsequent_data) + peak\n",
    "                    original_index = stroke_data.index[min_speed_index]\n",
    "                    stroke_data.loc[original_index, 'apex'] = 'AX'\n",
    "        else:\n",
    "            min_speed_index = np.argmin(stroke_data['right_wrist_speed'].values)\n",
    "            original_index = stroke_data.index[min_speed_index]\n",
    "            stroke_data.loc[original_index, 'apex'] = 'AX'\n",
    "        more_refined_apexes_df = more_refined_apexes_df._append(stroke_data)\n",
    "\n",
    "    # Save output\n",
    "    more_refined_apexes_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f'Done Processing {output_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
